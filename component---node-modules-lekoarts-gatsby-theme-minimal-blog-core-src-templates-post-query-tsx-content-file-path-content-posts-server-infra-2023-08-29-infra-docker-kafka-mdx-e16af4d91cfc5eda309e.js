"use strict";(self.webpackChunkgwiyeom_blog=self.webpackChunkgwiyeom_blog||[]).push([[9726],{7835:function(e,n,t){t.r(n),t.d(n,{Head:function(){return a.p},default:function(){return m}});var l=t(6540),r=t(8453);function o(e){const n=Object.assign({h1:"h1",p:"p",blockquote:"blockquote",ul:"ul",li:"li",a:"a",pre:"pre",code:"code",ol:"ol",hr:"hr",h3:"h3"},(0,r.RP)(),e.components);return l.createElement(l.Fragment,null,l.createElement(n.h1,null,"배경"),"\n",l.createElement(n.p,null,"토이 프로젝트로 경매프로그램을 만들기로 했다\n카푸카 개발 환경 셋팅,도커 셋팅을 담당하기로 했다."),"\n",l.createElement(n.h1,null,"카프카 특징"),"\n",l.createElement(n.p,null,"여러 컨슈머가 분산 처리로 메시지를 소비\n여러 서브스크라이버에 동일한 메시지 전달\n토픽 기반으로 전달 내용을 변경\n=> 컨슈머 그룹..설정\n스토리지 시스템\n(중요) 메시지를 잃지 않는다"),"\n",l.createElement(n.blockquote,null,"\n",l.createElement(n.p,null,"큐잉 모델\n브로커안에 큐를 준비해,프로듀서에서의 메시지가 큐에 담기고, 컨슈머가 큐에서 메시지를 추출\n하나의 큐에 대해 컨슈머가 여러 개 존재하며 컨슈머가 메시지를 받으면 다른 컨슈머는 받을 수 없다\n펍/섭 메시징 모델\n프로듀서= 퍼블리셔\n컨슈머 = 서브스크라이버\n퍼블리셔가 서브스크라이버에게 전달하는 것이 아니라 브로커를 통해서 전달\n퍼블리셔는 누가 그 메세지를 수신하는지 알 수 없고\n브로커에 있는 토픽이라고 불리는 카테고리 안에 메시지 등록\n여러 서브스크라이버가 동일한 토픽을 구독하기로 결정하면\n이 여러 서브스크라이버가 동일한 메시지를 받는다.\n또 다른 토픽에서는 다른 메시지를 받을 수 있다\n큐잉 모델,펍/섭 메시징 모델이든 모두 브로커를 사이에 끼우는 형태"),"\n"),"\n",l.createElement(n.ul,null,"\n",l.createElement(n.li,null,"오프셋\n어디까지 메시지를 받았는지 관리하기 위한 오프셋 존재\n오프셋 커밋은 메시지를 받아 정상적으로 처리를 완료한 다음 오프셋을 업데이트함\n컨슈머가 수신한 메시지를 정상 처리했다면 처리완료 기록을 브로커에 남긴다"),"\n"),"\n",l.createElement(n.h1,null,l.createElement(n.a,{href:"https://zeroco.tistory.com/105"},"카프카의 주요 용어")),"\n",l.createElement(n.blockquote,null,"\n",l.createElement(n.p,null,"목표 1:  카프카의 주요 용어 정리공부"),"\n"),"\n",l.createElement(n.p,null,"카프카(Kafka): 분산 스트리밍 플랫폼,대량의 데이터를 안정적으로 전송, 저장 및 처리할 수 있는 오픈 소스 메시지 큐 시스템"),"\n",l.createElement(n.ul,null,"\n",l.createElement(n.li,null,"메시지는 토픽에 순서대로 저장되며, 컨슈머는 메시지의 순서를 보장받을 수 있다."),"\n"),"\n",l.createElement(n.p,null,"Docker Cluster: Kafka 브로커, 프로듀서, 컨슈머 등이 실행되는 컨테이너 환경"),"\n",l.createElement(n.ul,null,"\n",l.createElement(n.li,null,"프로듀서와 컨슈머 이미지를 사용하여 Docker Compose 로 Docker 클러스터 내부에 컨테이너로 배포(실행)"),"\n",l.createElement(n.li,null,"Kafka 브로커는 Docker 컨테이너 내에서 실행되며 각 브로커는 다양한 토픽을 관리"),"\n"),"\n",l.createElement(n.pre,null,l.createElement(n.code,null,"+----------------------------- docker containers-----------------------------+\n|                                                                            |\n|                                 (zookeeper)                                |\n|                                      |                                     |\n|             \t           +-------(kafka cluster)-----+                     |\n| (Producer)--\x3e publish --\x3e|                           |--\x3eread--\x3e(Consumer) |\n|                          |                           |                     |\n|                          |  Leader  (kafka broker1)  |                     |\n|                          |  Follower(kafka broker2)  |                     |\n|                          |  Leader  (kafka broker3)  |                     |\n|                          |                           |                     |\n|                          +---------------------------+                     |\n+----------------------------------------------------------------------------+\n")),"\n",l.createElement(n.ol,null,"\n",l.createElement(n.li,null,"프로듀서 (Producer):"),"\n"),"\n",l.createElement(n.ul,null,"\n",l.createElement(n.li,null,"프로듀서는 데이터를 Kafka 토픽으로 보내는 역할을 합니다."),"\n",l.createElement(n.li,null,"데이터를 생성하고 Kafka 클러스터로 전송하여 토픽에 데이터를 게시합니다."),"\n"),"\n",l.createElement(n.ol,{start:"2"},"\n",l.createElement(n.li,null,"컨슈머 (Consumer):"),"\n"),"\n",l.createElement(n.ul,null,"\n",l.createElement(n.li,null,"컨슈머는 Kafka 토픽에서 데이터를 읽고 처리하는 역할을 합니다."),"\n",l.createElement(n.li,null,"컨슈머는 특정 토픽 또는 파티션에서 데이터를 구독합니다."),"\n"),"\n",l.createElement(n.ol,{start:"3"},"\n",l.createElement(n.li,null,"브로커 (Broker):"),"\n"),"\n",l.createElement(n.ul,null,"\n",l.createElement(n.li,null,"브로커는 Kafka 클러스터 내에서 메시지를 저장하고 관리하는 서버입니다."),"\n",l.createElement(n.li,null,"클러스터는 여러 브로커로 구성됩니다."),"\n"),"\n",l.createElement(n.ol,{start:"7"},"\n",l.createElement(n.li,null,"토픽 (Topic):"),"\n"),"\n",l.createElement(n.ul,null,"\n",l.createElement(n.li,null,"토픽은 Kafka에서 데이터 스트림을 카테고리화하는 메커니즘입니다."),"\n",l.createElement(n.li,null,"메시지를 특정 주제(토픽)에 게시하고 해당 토픽에서 메시지를 구독할 수 있습니다."),"\n"),"\n",l.createElement(n.ol,{start:"8"},"\n",l.createElement(n.li,null,"파티션 (Partition):"),"\n"),"\n",l.createElement(n.ul,null,"\n",l.createElement(n.li,null,"토픽은 하나 이상의 파티션으로 나뉩니다."),"\n",l.createElement(n.li,null,"각 파티션은 독립적인 로그 스트림이며, 데이터의 분산 처리를 지원하고 병렬로 처리됩니다."),"\n"),"\n",l.createElement(n.ol,{start:"4"},"\n",l.createElement(n.li,null,"리더 (Leader)와 팔로워 (Follower):"),"\n"),"\n",l.createElement(n.ul,null,"\n",l.createElement(n.li,null,"각 파티션은 하나의 리더와 여러 팔로워를 가질 수 있습니다."),"\n",l.createElement(n.li,null,"리더는 읽기와 쓰기 작업을 처리하고, 팔로워는 데이터를 동기화하여 신뢰성을 보장합니다."),"\n",l.createElement(n.li,null,"원본 = 리더(leader) 와 리플리케이션 = 팔로워(follower)로 구분"),"\n"),"\n",l.createElement(n.pre,null,l.createElement(n.code,null,"브로커 안에는 토픽이 있다\n토픽은 특정 주제나 카테고리에 속하는 메시지를 저장하는 논리적인 컨테이너\n각 토픽은 여러 파티션으로 나뉘며, 각 파티션은 메시지의 순서와 분산을 관리합니다.\n\n브로커는\n토픽과 그 안에 있는 파티션을 관리하여 메시지 스트림을 효과적으로 처리하고 분산합니다\n")),"\n",l.createElement(n.ol,{start:"5"},"\n",l.createElement(n.li,null,"프로듀서 컨펌 (Producer Acknowledgement):"),"\n"),"\n",l.createElement(n.ul,null,"\n",l.createElement(n.li,null,"프로듀서가 메시지를 보내고 성공적으로 받았음을 확인받는 방법을 나타냅니다."),"\n",l.createElement(n.li,null,"프로듀서 컨펌 설정에 따라 메시지 손실을 방지할 수 있습니다."),"\n"),"\n",l.createElement(n.ol,{start:"6"},"\n",l.createElement(n.li,null,"컨슈머 그룹 (Consumer Group):"),"\n"),"\n",l.createElement(n.ul,null,"\n",l.createElement(n.li,null,"여러 컨슈머가 하나의 토픽을 구독하고 데이터를 병렬로 처리할 수 있도록 그룹화된 구조입니다."),"\n",l.createElement(n.li,null,"각 컨슈머는 다른 파티션에서 작업하게 됩니다."),"\n"),"\n",l.createElement(n.ol,{start:"9"},"\n",l.createElement(n.li,null,"오프셋 (Offset):"),"\n"),"\n",l.createElement(n.ul,null,"\n",l.createElement(n.li,null,"오프셋은 파티션 내에서 메시지의 위치를 나타내는 오프셋 번호입니다."),"\n",l.createElement(n.li,null,"컨슈머는 특정 파티션에서 어디까지 메시지를 읽었는지를 오프셋을 사용하여 추적합니다."),"\n"),"\n",l.createElement(n.blockquote,null,"\n",l.createElement(n.p,null,l.createElement(n.a,{href:"https://collabnix.com/implementing-apache-kafka-on-docker-swarm-running-on-aws-platform-in-5-minutes/"},"Kafka의 데이터 흐름")),"\n"),"\n",l.createElement(n.pre,null,l.createElement(n.code,null,"[Producer] -> [Topic A Partition 1 Leader] -> [Broker 1]\n[Producer] -> [Topic A Partition 2 Leader] -> [Broker 2]\n[Producer] -> [Topic B Partition 0 Leader] -> [Broker 1]\n[Producer] -> [Topic B Partition 1 Leader] -> [Broker 2]\n")),"\n",l.createElement(n.ul,null,"\n",l.createElement(n.li,null,"Kafka 클러스터에 여러개의 브로커가 존재한다"),"\n",l.createElement(n.li,null,"브로커에는 여러 개의 토픽,파티션 존재"),"\n",l.createElement(n.li,null,"프로듀셔가 각각의 토픽 파티션에 맵핑하고 파티션의 리더에 요청을 보냄"),"\n"),"\n",l.createElement(n.hr),"\n",l.createElement(n.h1,null,"Docker로 카프카,주키퍼 띄우기"),"\n",l.createElement(n.blockquote,null,"\n",l.createElement(n.p,null,"목표 2 :"),"\n"),"\n",l.createElement(n.ul,null,"\n",l.createElement(n.li,null,"\n",l.createElement(n.p,null,"Docker로 카프카 서버 띄우기"),"\n"),"\n",l.createElement(n.li,null,"\n",l.createElement(n.p,null,"로컬에서 kafka 개발 환경 셋팅하고 실행"),"\n"),"\n",l.createElement(n.li,null,"\n",l.createElement(n.p,null,"docker-compose?\nDocker는 개별 컨테이너 관리에 사용되고\nDocker Compose는 여러 컨테이너로 구성된 애플리케이션 스택을 정의하고 관리하는 도구\nkafka 는 zookeeper 를 같이 사용해야 하기 때문에 docker-compose 설치"),"\n"),"\n"),"\n",l.createElement(n.p,null,l.createElement(n.code,null,"brew install docker-compose"),"\n",l.createElement(n.code,null,"docker-compose -v"),"\n",l.createElement(n.code,null,"docker-compose stop")," 실행한 서버 중지"),"\n",l.createElement(n.ul,null,"\n",l.createElement(n.li,null,"zookeeper?\n분산 코디네이션 서비스 :분산 시스템에서 서로 다른 노드 또는 서버 간에 상호 작용하고 조율하기 위한 도구\nex) zookeeper (레지스트리, 분산 락, 분산 큐 구현 등 다양한 분산 시스템에서 필요한 작업을 수행)\nex) etcd(클러스터 상태 및 설정 정보를 저장하고 공유)\n카프카에서는 리더 선출,분산 시스템관리,토픽 및 파티션 관리,브로커 디스커버리 등...위해서 사용"),"\n"),"\n",l.createElement(n.p,null,'도커 환경에서 카프카 컨테이너를 실행할 때 주키퍼 컨테이너를 실행해야 하는지 여부는 사용하는 카프카 버전과 설정에 따라 다를 수 있습니다.\n주키퍼(ZooKeeper)는 카프카의 이전 버전에서는 필수적으로 필요한 구성 요소였지만, 카프카 2.8.0 버전부터는 주키퍼 없이도 카프카를 실행할 수 있는 "KRaft" 모드가 도입되었습니다. KRaft 모드는 주키퍼 대신 내장된 상태 저장 기능을 사용하여 주키퍼의 의존성을 제거하고 카프카 클러스터를 더 단순하게 설정할 수 있도록 합니다.'),"\n",l.createElement(n.p,null,"따라서 카프카 2.8.0 버전 이상을 사용하는 경우, 주키퍼를 사용하지 않고도 카프카를 실행할 수 있습니다. 그러나 카프카 이전 버전을 사용하거나 특정 설정이 필요한 경우에는 주키퍼를 함께 실행해야 할 수 있습니다."),"\n",l.createElement(n.blockquote,null,"\n",l.createElement(n.ol,null,"\n",l.createElement(n.li,null,"Zookeeper, Kafka 컨테이너 이미지 가져오기위한 docker-compose 템플릿 작성"),"\n"),"\n"),"\n",l.createElement(n.p,null,l.createElement(n.code,null,"docker pull wurstmeister/zookeeper"),"\n",l.createElement(n.code,null,"docker pull wurstmeister/kafka"),"\n이렇게 집접 설치도 가능한데\n도커컴포즈.yml 에 ",l.createElement(n.code,null,"image:")," 추가해 이미지를 가져온다"),"\n",l.createElement(n.pre,null,l.createElement(n.code,{className:"language-yml"},'# compose 파일 버전\nversion: \'2\'\n\nservices:\n# 서비스 명\n  zookeeper:\n    # 사용할 이미지\n    image: wurstmeister/zookeeper\n    # 컨테이너명 설정\n    container_name: zookeeper\n    # 접근 포트 설정 (컨테이너 외부:컨테이너 내부)\n    ports:\n      - "2181:2181"\n# 서비스 명\n  kafka:\n     # 사용할 이미지\n    image: wurstmeister/kafka\n    # docker-compose 에서는 서비스들의 우선순위를 지정(kafka는 zookeeper가 먼저 실행되어야함)\n    depends_on:\n      - zookeeper\n    # 컨테이너명 설정\n    container_name: kafka\n    # kafka 브로커의 포트,접근 포트 설정 (컨테이너 외부:컨테이너 내부)\n    ports:\n      - "9094:9094"\n    # kafka 브로커를 위한 환경 변수 설정\n    environment:\n      KAFKA_ADVERTISED_HOST_NAME: 127.0.0.1\n      # Kafka 컨테이너가 시작될 때 Topic이라는 이름의 토픽을 생성하도록 지시 (Topic명:Partition개수:Replica개수)\n      KAFKA_CREATE_TOPICS: "myCustomTopic:1:1"\n      # 연결할 (서비스이름:컨테이너 내부 포트)\n      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181\n    # 볼륨 설정 :컨테이너 간 또는 호스트 시스템과 컨테이너 간에 데이터를 공유할 수 있으며, 컨테이너가 제거되더라도 데이터가 보존\n    # 호스트의 도커 소켓 파일(/var/run/docker.sock)을 컨테이너 내부의 동일한 경로로 마운트하는 것\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n')),"\n",l.createElement(n.ul,null,"\n",l.createElement(n.li,null,"마운트 = 주로 파일이나 디렉터리를 하나의 디렉터리 구조에서 다른 디렉터리 구조로 이동하거나 연결하는 작업"),"\n"),"\n",l.createElement(n.blockquote,null,"\n",l.createElement(n.ol,{start:"2"},"\n",l.createElement(n.li,null,"docker-compose  명령을 통해 컨테이너를 실행  (docker-compose 실행)"),"\n"),"\n"),"\n",l.createElement(n.p,null,l.createElement(n.code,null,"docker-compose -f docker-compose-single-broker.yml up -d")),"\n",l.createElement(n.p,null,"docker_compose.yml 일 경우\n이미지 빌드\n",l.createElement(n.code,null,"docker-compose up --build "),"\n만약 docker-compose-single-broker.yml 로 이름을 바꾸면 아래 명령어로 빌드\n",l.createElement(n.code,null,"docker-compose -f docker-compose-single-broker.yml up -d")),"\n",l.createElement(n.p,null,"-f (설정파일)을 통해서 우리가 작성한 설정으로 docker-compose를 실행한다.\nup 옵션을 통해 docker-compos 를 실행한다.\n-d 옵션은 detach 모드로 컨테이너를 백그라운드로 실행하게 해준다."),"\n",l.createElement(n.blockquote,null,"\n",l.createElement(n.ol,{start:"3"},"\n",l.createElement(n.li,null,"docker 상태 로그 확인"),"\n"),"\n"),"\n",l.createElement(n.p,null,l.createElement(n.code,null,"docker ps"),"\n",l.createElement(n.code,null,"docker logs 컨테이너ID")),"\n",l.createElement(n.blockquote,null,"\n",l.createElement(n.ol,{start:"4"},"\n",l.createElement(n.li,null,"컨테이너 중지,삭제"),"\n"),"\n"),"\n",l.createElement(n.p,null,l.createElement(n.code,null,"docker-compose down")),"\n",l.createElement(n.pre,null,l.createElement(n.code,null,"` docker-compose -f docker-compose-single-broker.yml down`\nkafka-docker-go-project > docker-compose down\n[+] Running 3/3\n✔ Container zookeeper                      Removed\n✔ Container kafka                          Removed\n✔ Network kafka-docker-go-project_default  Removed\n")),"\n",l.createElement(n.p,null,"컨테이너 가 멈추고 삭제된다\n이미지는 남아있고 볼륨도 있음"),"\n",l.createElement(n.hr),"\n",l.createElement(n.h1,null,"docker-compose 명령어로 topic 생성,확인,컨슈머 실행"),"\n",l.createElement(n.blockquote,null,"\n",l.createElement(n.p,null,"목표 2 :"),"\n"),"\n",l.createElement(n.ul,null,"\n",l.createElement(n.li,null,"topic 생성"),"\n",l.createElement(n.li,null,"컨슈머 실행 = 브로커로 부터 메시지를 수신"),"\n",l.createElement(n.li,null,"프로듀서 실행 = 프로듀서로 메시지를 전송"),"\n"),"\n",l.createElement(n.hr),"\n",l.createElement(n.h3,null,"카푸카 클라이언트 예제 코드 (프로듀서,컨슈머)"),"\n",l.createElement(n.p,null,l.createElement(n.a,{href:"https://github.com/confluentinc/confluent-kafka-go"},"https://github.com/confluentinc/confluent-kafka-go")),"\n",l.createElement(n.blockquote,null,"\n",l.createElement(n.ol,{start:"0"},"\n",l.createElement(n.li,null,"kafka에 접속하기"),"\n"),"\n"),"\n",l.createElement(n.p,null,l.createElement(n.code,null,"docker container exec -it {컨테이너이름} bash"),"\nex) docker container exec -it kafka bash"),"\n",l.createElement(n.blockquote,null,"\n",l.createElement(n.ol,null,"\n",l.createElement(n.li,null,"토픽 생성"),"\n"),"\n"),"\n",l.createElement(n.p,null,l.createElement(n.code,null,"kafka-topics.sh --create --topic test-topic --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1")),"\n",l.createElement(n.blockquote,null,"\n",l.createElement(n.ol,{start:"2"},"\n",l.createElement(n.li,null,"생성된 토픽 목록 보기"),"\n"),"\n"),"\n",l.createElement(n.p,null,l.createElement(n.code,null,"kafka-topics.sh --list --bootstrap-server localhost:9092")),"\n",l.createElement(n.pre,null,l.createElement(n.code,null,"root:/# cd bin\nroot:/bin# kafka-console-producer.sh --broker-list localhost:9092 --topic test-topic\n> 메세지 보낸다 받아라\n")),"\n",l.createElement(n.blockquote,null,"\n",l.createElement(n.ol,{start:"3"},"\n",l.createElement(n.li,null,"프로듀서 실행"),"\n"),"\n"),"\n",l.createElement(n.p,null,l.createElement(n.code,null,"kafka-console-producer.sh --broker-list localhost:9092 --topic test-topic")),"\n",l.createElement(n.pre,null,l.createElement(n.code,null,"root:/# cd bin\nroot:/bin# kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test-topic --from-beginning\n\n메세지 보낸다 받아라\n")),"\n",l.createElement(n.blockquote,null,"\n",l.createElement(n.ol,{start:"5"},"\n",l.createElement(n.li,null,"토픽 삭제"),"\n"),"\n"),"\n",l.createElement(n.p,null,l.createElement(n.code,null,"kafka-topics.sh --bootstrap-server localhost:9092 --topic test-topic --delete"),"\n",l.createElement(n.code,null,"kafka-topics.sh --delete --zookeeper zookeeper:2181 --topic test-topic")),"\n",l.createElement(n.blockquote,null,"\n",l.createElement(n.ol,{start:"6"},"\n",l.createElement(n.li,null,"주의"),"\n"),"\n"),"\n",l.createElement(n.ul,null,"\n",l.createElement(n.li,null,"토픽 이름(topic names)"),"\n"),"\n",l.createElement(n.pre,null,l.createElement(n.code,null,"Due to limitations in metric names, topics with a period ('.') or underscore ('_') could collide.\nTo avoid issues it is best to use either, but not both.\n\n마침표 (.)나 밑줄 (_) 중 하나만 사용하세요. 예를 들어 my_topic 또는 my.topic 중 하나를 선택하는 것이 좋지만,\n토픽 이름에서 마침표와 밑줄을 피하세요.\n다른 문자 (예: 알파벳, 숫자, 하이픈 등)을 사용하여 메트릭 이름과 충돌할 가능성을 줄이세요\n")),"\n",l.createElement(n.p,null,l.createElement(n.a,{href:"https://medium.com/@kiranprabhu/kafka-topic-naming-conventions-best-practices-6b6b332769a3"},"https://medium.com/@kiranprabhu/kafka-topic-naming-conventions-best-practices-6b6b332769a3")),"\n",l.createElement(n.ul,null,"\n",l.createElement(n.li,null,"토픽 삭제 전에 설정 필요"),"\n"),"\n",l.createElement(n.p,null,l.createElement(n.code,null,"docker container exec -it kafka bash ")," 로 컨테이너에 접근 후"),"\n",l.createElement(n.p,null,l.createElement(n.code,null,"root> cd /opt/kafka/config "),"로 이동 ",l.createElement(n.code,null,"server.properties")," 있음"),"\n",l.createElement(n.ul,null,"\n",l.createElement(n.li,null,l.createElement(n.code,null,"server.properties")," (Kafka의 서버 설정 파일) 파일의 내용을 수정하려면 ",l.createElement(n.code,null,"vim server.properties")),"\n"),"\n",l.createElement(n.p,null,l.createElement(n.code,null,"vim"),"을 docker container 에서 사용하려면 아래 방법으로 다운"),"\n",l.createElement(n.pre,null,l.createElement(n.code,null,"docker container exec -it {container이름}  bash\napt-get update\napt-get install vim\n")),"\n",l.createElement(n.p,null,l.createElement(n.code,null,"server.properties")," 파일에 ",l.createElement(n.code,null,"delete.topic.enable = true")," 를 추가한다"),"\n",l.createElement(n.ul,null,"\n",l.createElement(n.li,null,"\n",l.createElement(n.p,null,l.createElement(n.code,null,"server.properties")," 을 변경후 kafka 컨테이너 재시작 해야한다"),"\n"),"\n",l.createElement(n.li,null,"\n",l.createElement(n.p,null,"Zookeeper의 서버 설정 파일 = zookeeper.properties"),"\n"),"\n",l.createElement(n.li,null,"\n",l.createElement(n.p,null,"가끔..토픽을 삭제했는데 (설정도 완료했는데).. 삭제 안된다면 다시 카프카 서버를 재시작해본다."),"\n"),"\n"),"\n",l.createElement(n.h1,null,"참고"),"\n",l.createElement(n.p,null,l.createElement(n.a,{href:"https://bsssss.tistory.com/1110"},"https://bsssss.tistory.com/1110"),"\n",l.createElement(n.a,{href:"https://yes-admit.tistory.com/74"},"https://yes-admit.tistory.com/74"),"\n",l.createElement(n.a,{href:"https://tommypagy.tistory.com/226"},"https://tommypagy.tistory.com/226"),"\n",l.createElement(n.a,{href:"https://akageun.github.io/2019/09/10/docker-compose-local-kafka.html"},"https://akageun.github.io/2019/09/10/docker-compose-local-kafka.html"),"\n",l.createElement(n.a,{href:"https://www.sktenterprise.com/bizInsight/blogDetail/dev/2565"},"https://www.sktenterprise.com/bizInsight/blogDetail/dev/2565"),"\n",l.createElement(n.a,{href:"https://bsssss.tistory.com/1110"},"https://bsssss.tistory.com/1110"),"\n",l.createElement(n.a,{href:"https://stackoverflow.com/questions/31515863/how-to-run-vi-on-docker-container"},"https://stackoverflow.com/questions/31515863/how-to-run-vi-on-docker-container"),"\n",l.createElement(n.a,{href:"https://velog.io/@jinmin2216/Kafka-Docker-%EC%84%A4%EC%B9%98%EB%B6%80%ED%84%B0-Kafka-Quick-Start%EA%B9%8C%EC%A7%80"},"https://velog.io/@jinmin2216/Kafka-Docker-설치부터-Kafka-Quick-Start까지"),"\n",l.createElement(n.a,{href:"https://dev-youngjun.tistory.com/259"},"https://dev-youngjun.tistory.com/259"),"\n",l.createElement(n.a,{href:"https://www.sktenterprise.com/bizInsight/blogDetail/dev/2565"},"https://www.sktenterprise.com/bizInsight/blogDetail/dev/2565"),"\n",l.createElement(n.a,{href:"https://tychejin.tistory.com/361"},"https://tychejin.tistory.com/361"),"\n",l.createElement(n.a,{href:"https://tommypagy.tistory.com/226"},"https://tommypagy.tistory.com/226"),"\n",l.createElement(n.a,{href:"https://cornswrold.tistory.com/524"},"https://cornswrold.tistory.com/524"),"\n",l.createElement(n.a,{href:"https://code-lab1.tistory.com/236"},"https://code-lab1.tistory.com/236"),"\n",l.createElement(n.a,{href:"https://devocean.sk.com/blog/techBoardDetail.do?ID=164007"},"https://devocean.sk.com/blog/techBoardDetail.do?ID=164007"),"\n",l.createElement(n.a,{href:"https://github.com/confluentinc/confluent-kafka-go"},"https://github.com/confluentinc/confluent-kafka-go"),"\n",l.createElement(n.a,{href:"https://www.daleseo.com/docker-run/"},"https://www.daleseo.com/docker-run/"),"\n",l.createElement(n.a,{href:"https://www.yalco.kr/36_docker/"},"https://www.yalco.kr/36_docker/"),"\n",l.createElement(n.a,{href:"https://github.com/wurstmeister/kafka-docker/blob/master/docker-compose-single-broker.yml"},"https://github.com/wurstmeister/kafka-docker/blob/master/docker-compose-single-broker.yml"),"\n",l.createElement(n.a,{href:"https://shortstories.gitbook.io/studybook/go/go-in-action/8c7a5-d45c-c900-b77c-c774-be0c-b7ec-b9ac"},"https://shortstories.gitbook.io/studybook/go/go-in-action/8c7a5-d45c-c900-b77c-c774-be0c-b7ec-b9ac"),"\n",l.createElement(n.a,{href:"https://seongjin.me/raft-consensus-algorithm"},"https://seongjin.me/raft-consensus-algorithm"),"\n",l.createElement(n.a,{href:"https://akageun.github.io/2019/09/10/docker-compose-local-kafka.html/"},"https://akageun.github.io/2019/09/10/docker-compose-local-kafka.html/"),"\n",l.createElement(n.a,{href:"https://velog.io/@holicme7/Apache-Kafka-%EC%B9%B4%ED%94%84%EC%B9%B4%EB%9E%80-%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80"},"https://velog.io/@holicme7/Apache-Kafka-%EC%B9%B4%ED%94%84%EC%B9%B4%EB%9E%80-%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80"),"\n",l.createElement(n.a,{href:"https://engineering.linecorp.com/ko/blog/how-to-use-kafka-in-line-1"},"https://engineering.linecorp.com/ko/blog/how-to-use-kafka-in-line-1")))}var c=function(e){void 0===e&&(e={});const{wrapper:n}=Object.assign({},(0,r.RP)(),e.components);return n?l.createElement(n,e,l.createElement(o,e)):o(e)},a=t(7292);function m(e){return l.createElement(a.A,e,l.createElement(c,e))}a.A}}]);
//# sourceMappingURL=component---node-modules-lekoarts-gatsby-theme-minimal-blog-core-src-templates-post-query-tsx-content-file-path-content-posts-server-infra-2023-08-29-infra-docker-kafka-mdx-e16af4d91cfc5eda309e.js.map